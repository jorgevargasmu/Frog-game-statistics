---
title: "Accuracy"
author: "Jorge VM"
date: "2024-07-06"
output: html_document
---

```{r}
library(lme4)
library(ggplot2)
library(performance)
library(DHARMa)
library(lmerTest)
library(tidyverse)
library(emmeans)
library(gridExtra)
```


```{r}
data <- read_csv("filtered_data.csv")


data <- data %>%
  mutate(
    Player_ID = as.factor(Player_ID),          # Convert to factor
    LexTale = as.numeric(LexTale),              # Convert to numeric
    Game_Version = as.factor(Game_Version),     # Convert to factor
    Game_Level = as.factor(Game_Level),        # Convert to factor
    Phrase_Condition = as.factor(Phrase_Condition), # Convert to factor
    Question_Num = as.numeric(Question_Num),    # Convert to numeric
    Answer = as.numeric(Answer),                 # Convert to factor
    Reaction_Time = as.numeric(Reaction_Time)   # Convert to numeric
  )

# Verify changes

str(data)

```

```{r}
# Dataframe for learning (Accuracy over Time)
data_learning <- data %>%
  group_by(Player_ID, Question_Num) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')

# Dataframe for hardest condition
data_condition <- data %>%
  group_by(Player_ID, Phrase_Condition) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')

# Dataframe for the impact of different versions
data_version <- data %>%
  group_by(Player_ID, Game_Version) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')

# Dataframe for rate of improvement depending on the version and condition
data_improvement <- data %>%
  group_by(Player_ID, Question_Num, Phrase_Condition, Game_Version) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')
```
#0. Accuracy marginalizing over everything

```{r}
# Dataframe for overall average accuracy per participant
data_ac <- data %>%
  group_by(Player_ID) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')

# Fit the model
model2 <- lm(Average_Accuracy ~ 1, data = data_ac)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model2))
```
```{r}
#Diagnostic plots
#plot_residuals_diagnostics(model2)
plot(model2)
```

```{r}
# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model2, n = 500)
plot(residuals_simulation)
```
```{r}
# Model diagnostics
check_model(model2)
```
# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

4b: ac - 1 + condition * version + (1 + condition | participant)

```{r}
# Dataframe for condition and version interaction
data_condition_version <- data %>%
  group_by(Player_ID, Phrase_Condition, Game_Version) %>%
  summarise(Average_Accuracy = mean(Answer), .groups = 'drop')

#This doesnt work:
#model4 <- lmer(Average_Accuracy ~ 1 + Phrase_Condition * Game_Version + (1 + Phrase_Condition | Player_ID), data = data_condition_version)
model4 <- lmer(Average_Accuracy ~ 1 + Phrase_Condition * Game_Version + (1 | Player_ID), data = data_condition_version)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model4))
```
## 
## Correlation matrix not shown by default, as p = 16 > 12.
## Use print(summary(model4), correlation=TRUE)  or
##     vcov(summary(model4))        if you need it

```{r}
#Diagnostic plots
plot_residuals_diagnostics(model4)
```
## `geom_smooth()` using formula = 'y ~ x'

```{r}
# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model4, n = 500)
plot(residuals_simulation)

```

```{r}
# Model diagnostics
check_model(model4)
```


```{r}
# Check for influential cases potentially affecting the model
#influence_measures <- influence(model4)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
fixed_effects <- fixef(model4)
random_effects <- ranef(model4)

# Printing fixed effects for interpretation
print(fixed_effects)
```

#check above result, different from the other one. 

```{r}
# Printing random effects for interpretation
print(random_effects)
```

```{r}
# Conducting pairwise comparisons of phrase conditions using estimated marginal means
emm_results <- emmeans(model4, specs = pairwise ~ Phrase_Condition)
```

```{r}
print(summary(emm_results))
```
## 0. What is the average reaction time marginalizing over everything?

```{r }
model1 <- lmer(Average_Accuracy ~ 1 + (1 | Player_ID), data_ac)


#Error: number of levels of each grouping factor must be < number of observations (problems: Player_ID)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model1))

#Diagnostic plots
plot_residuals_diagnostics(model1)

# Model diagnostics
check_model(model1)
```

## 1. Does learning take place?
```{r }
model2 <- lmer(Average_Accuracy ~ 1 + Question_Num + (1 + Question_Num | Player_ID), data_learning)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model2))

#Diagnostic plots
plot_residuals_diagnostics(model2)

# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model2, n = 500)
plot(residuals_simulation)

# Model diagnostics
check_model(model2)

# Check for influential cases potentially affecting the model
#influence_measures <- influence(model3)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
#fixed_effects <- fixef(model3)
#random_effects <- ranef(model3)

# Printing fixed effects for interpretation
#print(fixed_effects)

# Printing random effects for interpretation
#print(random_effects)

# Get estimated marginal means for specific values of Question_Num
emm_results <- emmeans(model2, specs = ~ Question_Num, at = list(Question_Num = seq(min(data$Question_Num), max(data$Question_Num), by = 10)))

# Summarize the results
summary(emm_results)

# Plot the estimated marginal means
plot(emm_results)


```
```{r }
# Create a plot of Average_Accuracy vs. Question_Num with a regression line
ggplot(data_learning, aes(x = Question_Num, y = Average_Accuracy)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Average Accuracy vs. Question Number",
       x = "Question Number",
       y = "Average_Accuracy")
```
## 2. Which condition is the hardest overall?

```{r }
#model3 <- lmer(Average_Accuracy ~ 1 + Phrase_Condition + (1 + Phrase_Condition | Player_ID), data_condition) - error

model3 <- lmer(Average_Accuracy ~ 1 + (1 + Phrase_Condition | Player_ID), data_condition)

#Error: number of observations (=152) <= number of random effects (=152) for term (1 + Phrase_Condition | Player_ID); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model3))

#Diagnostic plots
plot_residuals_diagnostics(model3)

# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model3, n = 500)
plot(residuals_simulation)

# Model diagnostics
check_model(model3)

# Check for influential cases potentially affecting the model
#influence_measures <- influence(model3)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
#fixed_effects <- fixef(model3)
#random_effects <- ranef(model3)

# Printing fixed effects for interpretation
#print(fixed_effects)

# Printing random effects for interpretation
#print(random_effects)

# Conducting pairwise comparisons of phrase conditions using estimated marginal means
emm_results <- emmeans(model3, specs = ~ Phrase_Condition)
summary(emm_results)
pairwise_comparisons <- emmeans(model3, specs = pairwise ~ Phrase_Condition)
summary(pairwise_comparisons)
plot(emm_results)
```

```{r }
# Create a boxplot
ggplot(data_condition, aes(x = Phrase_Condition, y = Average_Accuracy, fill = Phrase_Condition)) +
  geom_boxplot() +
  labs(title = "Average Accuracy by Phrase Condition", x = "Phrase Condition", y = "Accuracy (seconds)") +
  theme_minimal()
```

```{r }
# Calculate average acc per player per condition
avg_reaction_times <- data %>%
  group_by(Player_ID, Phrase_Condition) %>%
  summarise(Avg_Reaction_Time = mean(Reaction_Time), .groups = 'drop')

# Interaction plot
ggplot(avg_reaction_times, aes(x = Phrase_Condition, y = Avg_Reaction_Time, group = Player_ID, color = Phrase_Condition)) +
  geom_line(alpha = 0.5) +  # Slightly transparent to see overlapping lines
  geom_point() +
  labs(title = "Interaction of Phrase Condition and Player on Reaction Times", x = "Phrase Condition", y = "Average Reaction Time (seconds)") +
  theme_minimal()
```

## 3. Does the version of the experiment cause different outcomes?
```{r}
model8 <- lmer(Average_Accuracy ~ 1 + Game_Version + (1 | Player_ID), data_version, control=lmerControl(check.nobs.vs.nlev = "ignore",
     check.nobs.vs.rankZ = "ignore",
     check.nobs.vs.nRE="ignore"))

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model8))

#Diagnostic plots
plot_residuals_diagnostics(model8)

# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model8, n = 500)
plot(residuals_simulation)

# Model diagnostics
check_model(model8)

# Check for influential cases potentially affecting the model
#influence_measures <- influence(model4)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
fixed_effects <- fixef(model8)
random_effects <- ranef(model8)

```

## 4. How does the effect of condition vary depending on the version?

```{r }
#This doesnt work:
#model4 <- lmer(Average_Accuracy ~ 1 + Phrase_Condition * Game_Version + (1 + Phrase_Condition | Player_ID), data = data)

model4 <- lmer(Average_Accuracy ~ 1 + Phrase_Condition * Game_Version + (1 | Player_ID), data_condition_version)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model4))

#Diagnostic plots
plot_residuals_diagnostics(model4)

# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model4, n = 500)
plot(residuals_simulation)

# Model diagnostics
check_model(model4)

# Check for influential cases potentially affecting the model
#influence_measures <- influence(model4)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
fixed_effects <- fixef(model4)
random_effects <- ranef(model4)

# Printing fixed effects for interpretation
print(fixed_effects)

# Printing random effects for interpretation
print(random_effects)

# Estimate marginal means for all combinations
emm1 <- emmeans(model4, specs = ~ Phrase_Condition * Game_Version)
summary(emm1)

# Pairwise comparisons across phrase conditions within each game version
pairs(emm1, simple = "each")

plot(emm1)
```

## 5. Does the rate of improvement in each condition depend on the version?
```{r }
model5 <- lmer(Average_Accuracy ~ 1 + Question_Num + Phrase_Condition * Game_Version + (1 | Player_ID), data_improvement)

# Obtain and print a summary of the model to examine fixed and random effects
print(summary(model5))

#Diagnostic plots
plot_residuals_diagnostics(model5)

# Diagnostic checks - Simulating residuals to validate model assumptions
residuals_simulation <- simulateResiduals(fittedModel = model5, n = 500)
plot(residuals_simulation)

# Model diagnostics
check_model(model5)

# Check for influential cases potentially affecting the model
#influence_measures <- influence(model5)
#plot(influence_measures, which = "cook")

# If assumptions are not met, consider re-fitting the model with transformations or different specifications
# model_revised <- update(model, . ~ . + log(Reaction_Time))
# print(summary(model_revised))

# Model interpretation - examining fixed and random effects
fixed_effects <- fixef(model5)
random_effects <- ranef(model5)

# Printing fixed effects for interpretation
print(fixed_effects)

# Printing random effects for interpretation
print(random_effects)

# Estimate marginal means at various levels of Question_Num
emm2 <- emmeans(model5, specs = ~ Phrase_Condition * Game_Version, at = list(Question_Num = c(1, 10, 20)))
summary(emm2)

# Trend analysis
trend_analysis <- emtrends(model5, specs = ~ Phrase_Condition * Game_Version, var = "Question_Num")
summary(trend_analysis)

plot(emm2)

```
