---
title: "Accuracy Logistic Regression"
author: "Juan M Gonzlez"
date: "2024-07-06"
output: html_document
---

```{r, setup, include=FALSE}
library(lme4)
library(ggplot2)
library(performance)
library(DHARMa)
library(lmerTest)
library(tidyverse)
library(emmeans)
library(gridExtra)
library(ROCR)




# Load necessary libraries
library(lme4)
library(ROCR)

# Define the function to plot diagnostics for logistic mixed-effects models
plotModelDiagnostics <- function(model, data) {
  # Deviance Residuals Plot
  dev_res <- resid(model, type = "deviance")
  plot(dev_res, ylim = c(min(dev_res), max(dev_res)), main = "Deviance Residuals")
  abline(h = 0, col = "red")
  
  # ROC Curve and AUC calculation
  probabilities <- predict(model, type = "response")
  actual <- data$Answer
  pred <- prediction(probabilities, actual)
  perf <- performance(pred, "tpr", "fpr")
  
  # Plot ROC Curve
  plot(perf, main = "ROC Curve")
  abline(0, 1, col = "blue")  # Adding diagonal line for reference
  
  # Calculate AUC and display it
  auc <- performance(pred, "auc")
  auc_value <- auc@y.values[[1]]
  cat("Area Under the Curve (AUC):", auc_value, "\n")
  
  # Simple plot just showing AUC value
  plot(1, type = "n", axes = FALSE, xlab = "", ylab = "", main = "AUC Value")
  text(1, 1, labels = paste("AUC =", round(auc_value, 3)), cex = 2)
}

# Example of using the function (you should already have a model fitted)
# plotModelDiagnostics(model1, data)
```


```{r}
data <- read.csv("/Users/jorgevargasmutizabal/Desktop/Frog game statistics/R Analysis Frog/filtered_data.csv")

data <- data %>%
  mutate(
    Player_ID = as.factor(Player_ID),          # Convert to factor
    LexTale = as.numeric(LexTale),              # Convert to numeric
    Game_Version = as.factor(Game_Version),     # Convert to factor
    Game_Level = as.factor(Game_Level),        # Convert to factor
    Phrase_Condition = as.factor(Phrase_Condition), # Convert to factor
    Question_Num = as.numeric(Question_Num),    # Convert to numeric
    Answer = as.numeric(Answer),                 # Convert to factor
    Reaction_Time = as.numeric(Reaction_Time)   # Convert to numeric
  )

# Verify changes
str(data)
```

# Why Logistic regression?

Logistic regression is a powerful statistical tool used primarily when the outcome you're studying is binary, like yes/no or success/failure scenarios. It differs from linear regression by predicting probabilities that are constrained between 0 and 1, using a logistic function. This approach provides insights into how likely an event is to occur, offering interpretable results such as odds ratios, which describe how the likelihood of the outcome changes with different predictor variables. Logistic regression is particularly useful because it can handle non-linear relationships, include random effects to account for variability across subjects in studies like surveys or experiments, and is robust against model overfitting through techniques like regularization.

## 0. Accuracy marginalizing over everything

Accounting for variability among participants (participants as a random effect)
Oa: ac ~ 1 + (1 | participant)

```{r}
# Fit a basic logistic mixed-effects model
model0 <- glmer(Answer ~ 1 + (1 | Player_ID), data=data, family=binomial)

summary(model0)

plotModelDiagnostics(model0, data)
```

## Interpretation
Fixed Effects

Intercept (1.69897): The intercept in a logistic regression model represents the log odds of the dependent variable (correct answer, coded as 1) when all other predictors are at their reference levels. In this case, since there are no other predictors, it represents the baseline log odds of giving a correct answer for a "typical" player, accounting for random variation among players.
Converting Log Odds to Probability: The probability of a correct answer can be calculated from the log odds using the logistic function. For the intercept of 1.69897, the probability 
p is: = 1.698971 + 1.69897 ≈ 0.845 p= 1+e 1.69897 e 1.69897 ≈ 0.845
This means the average probability of a correct answer across all players, adjusted for individual differences, is about 84.5%.

Random Effects

Player_ID (Variance: 0.1471, Std.Dev.: 0.3835): This indicates the variability in the log odds of correct answers among players. The standard deviation of 0.3835 suggests that the baseline performance in terms of log odds varies by this amount among players around the fixed effect intercept.
Interpretation: A higher standard deviation implies greater variability in performance among players. If the standard deviation were close to zero, it would suggest that the performance across players is very similar.

Deviance Residuals Plot
Deviance residuals are a type of residual used for logistic regression that can help identify misfitting observations or regions of the data that the model does not adequately describe. Here’s what to look for in the deviance residuals plot:
No Systematic Patterns: Ideally, you want to see a random scatter of residuals against fitted values or another variable of interest. Systematic patterns might suggest a misspecification in the model such as missing important predictors or interactions.
Outliers: Look for extreme values in the residuals. Very large or very small residuals indicate observations that are poorly predicted by the model. These could be potential outliers or influential points that might warrant further investigation.
Fixed Number of Possible Residuals: Each predicted probability corresponding to an actual outcome of 0 or 1 can only result in a limited set of possible residuals. This is why you see distinct bands:
Positive Residuals (~0.5): These typically occur when the model predicts a low probability of the event (correct answer), but the actual outcome is 1 (correct). The residual calculation here reflects that the model under-predicted the probability of a correct answer.
Negative Residuals (~-2.0): These occur when the model predicts a high probability of the event, but the actual outcome is 0 (incorrect). The residual reflects that the model over-predicted the probability of a correct answer.

ROC Curve
The ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It is created by plotting the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings. The Area Under the Curve (AUC) provides a single measure of how well the model discriminates between the two classes (correct vs. incorrect answers) across all possible thresholds:

Shape of the Curve: A curve that climbs quickly towards the top-left corner of the plot indicates a model with good discriminative ability. The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.
AUC Value: The AUC ranges from 0 to 1, where 0.5 denotes a model with no discriminative ability (equivalent to random guessing), and 1 denotes perfect discrimination. An AUC closer to 1 indicates a better model. In your case, an AUC of 0.6126 suggests that the model has better than random but moderate discriminative power. Improving this could involve adding predictive features to the model or reconsidering some aspects of the model structure.

##Does learning take place?

1: ac - 1 + time + (1 + time | participant)

```{r}
control <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1000000))
model1 <- glmer(Answer ~ 1 + Question_Num + (1 + Question_Num | Player_ID), data = data, family = binomial, control = control)

summary(model1)

plotModelDiagnostics(model1, data)

```


## 2. Which condition is hardest overall?

2: ac - 1 + condition + (1 + condition | participant)


```{r}
control <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1000000))
model2 <- glmer(Answer ~ 1 + Phrase_Condition + (1 + Phrase_Condition | Player_ID), data = data, family = binomial, control = control)


# Output the summary of the model to see the results
summary(model2)

plotModelDiagnostics(model2, data)
```
## Interpretation

Model Output Interpretation
Fixed Effects: The coefficients for Phrase_Condition2, Phrase_Condition3, and Phrase_Condition4 are significant, with negative signs indicating these conditions are associated with lower odds of a correct answer compared to the baseline condition (Phrase_Condition1).
Phrase_Condition4 shows the largest negative coefficient (-2.7357), suggesting it is the hardest condition, as it substantially decreases the odds of a correct answer.
Random Effects: There is considerable variability in intercepts and slopes for Phrase_Condition across players. The standard deviations are significant, indicating variability in player responses to different conditions.
Correlations: The correlations between intercepts and slopes (for different conditions) are notable, especially between Phrase_Condition4 and the intercept, suggesting that players who find the baseline condition easier or harder tend to also find Phrase_Condition4 proportionally easier or harder.
AUC (Area Under the Curve)
The AUC of 0.7629 indicates good discriminative ability of the model to distinguish between correct and incorrect answers. This value is quite satisfactory, suggesting that the model does a good job overall in classifying the outcomes based on the conditions and individual player effects.


You can do this with pretty much any other mode. Keep in mind that you have to do log conversion of the probabilities.

##Does the version of the experiment cause different outcomes?

ac - 1 + version + ((1 | participant)

```{r}
control <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1000000))
model3 <- glmer(Answer ~ 1 + Game_Version + (1 | Player_ID), data = data, family = binomial, control = control)


summary(model3)

plotModelDiagnostics(model3, data)
```

##Hoes does the effect of condition vary depending on the version?

ac - 1 + condition * version + (1 + condition | participant)

```{r}
control <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1000000))
model4 <- glmer(Answer ~ 1 + Phrase_Condition * Game_Version + (1 | Player_ID), data = data, family = binomial, control = control)

summary(model4)

plotModelDiagnostics(model4, data)

```

Does the rate of improvement in each condition depend on the version?
##ac - 1 + time + condition * version + (1 + time + condition | participant)

```{r}
control <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1000000))
model5 <- glmer(Answer ~ 1 + Question_Num + Phrase_Condition * Game_Version + (1 | Player_ID), data = data, family = binomial, control = control)

summary(model5)

plotModelDiagnostics(model5, data)
```

